{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "GIS @ <a href=\"https://geoai-webgis-ent.bd.esri.com/portal\">https://geoai-webgis-ent.bd.esri.com/portal</a>"
      ],
      "text/plain": [
       "GIS @ https://geoai-webgis-ent.bd.esri.com/portal version:7.1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.env import active_gis\n",
    "from arcgis.features import GeoAccessor\n",
    "from arcgis.geometry import Geometry\n",
    "from arcgis import geoenrichment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/geoai_retail')\n",
    "import utils\n",
    "import config\n",
    "from enrich_rest import enrich, get_online_variable_list\n",
    "\n",
    "ent_gis = GIS(config.ent_url, username=config.ent_user, password=config.ent_pass)\n",
    "ent_gis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VoeAmzcqtpo2Op7iHUQWbvxSUsC0nFXEsFsEaZO5x2VZ9K-iu99sBp7WdFn87CsN4XdsN_PkzUMgokFh41gtWHYuXYs6dujvtpb7lsy9Hg15a2G7WQK2Rgs_5BpZRHWA'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gis = ent_gis\n",
    "gis._con.relogin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PippaRZJ1MbJOz4qi__HKO-OKJyxhYPO_x1j2SsrsNILi_-r4IRqrSaWGXzZKgAvaVGbu0Z8S8F2T7KFSFm-cnpnq2AU7jK2LmX0LLOXPjJ4S8oHG8pnWPlYT4GigB-a'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gis._con.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://geoai-webgis-ba.bd.esri.com/server/rest/services/World/GeoEnrichmentServer'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gis.properties.helperServices.geoenrichment.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gdb = r'../data/raw/raw.gdb'\n",
    "origin_fc = os.path.join(raw_gdb, 'blocks')\n",
    "origin_id_fld = 'GEOID'\n",
    "\n",
    "geo_fc = origin_fc\n",
    "geo_id_fld = origin_id_fld\n",
    "\n",
    "vars_csv = '../data/raw/enrichment_variables.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from functools import reduce\n",
    "import tempfile\n",
    "import uuid\n",
    "\n",
    "# location to store temp files if necessary\n",
    "csv_file_prefix = 'temp_enrich'\n",
    "temp_file_root = os.path.join(tempfile.gettempdir(), csv_file_prefix)\n",
    "\n",
    "\n",
    "def get_online_variable_list(variable_list_to_lookup, gis, exclude_five_year_projections=True):\n",
    "    \"\"\"\n",
    "    From an input variable list derived from a dataset already enriched, use ArcGIS Online to look up a list of enrichment\n",
    "        variables to use for performing enrichment on another new dataset.\n",
    "    :param variable_list_to_lookup: List of field/column names from an dataset already enriched.\n",
    "    :param exclude_five_year_projections: Boolean to indicate if to consider the future year (five year projection) variables.\n",
    "    \"\"\"\n",
    "    # get the data available in the USA\n",
    "    usa = geoenrichment.Country.get('USA')\n",
    "    enrich_df = usa.data_collections\n",
    "    \n",
    "    # if excluding the five year projections, drop them out\n",
    "    if exclude_five_year_projections:\n",
    "        five_year_out = str(np.max([int(val) for val in enrich_df['vintage'].unique() if pd.notna(val) and not '-' in val]))\n",
    "        enrich_df = enrich_df[enrich_df['vintage'] != five_year_out].copy()\n",
    "    \n",
    "    # slice off the variable name in a separate column\n",
    "    enrich_df['variable_name'] = enrich_df['analysisVariable'].apply(lambda val: val.split('.')[1])\n",
    "    \n",
    "    # drop any variable name duplicates\n",
    "    enrich_df = enrich_df.drop_duplicates('variable_name')\n",
    "    \n",
    "    # flag variables we want to use for enriching the new data\n",
    "    var_match = enrich_df['variable_name'].apply(lambda var_name: var_name in variable_list_to_lookup)\n",
    "    \n",
    "    # create a list of the analysis variables usable for enrichment\n",
    "    return list(enrich_df[var_match]['analysisVariable'].values)\n",
    "\n",
    "\n",
    "def get_enrichment_alias_dataframe(variable_list_to_lookup, gis):\n",
    "    \n",
    "    # get the data available in the USA\n",
    "    usa = geoenrichment.Country.get('USA')\n",
    "    enrich_df = usa.data_collections\n",
    "    \n",
    "    # slice off the variable name in a separate column\n",
    "    enrich_df['variable_name'] = enrich_df['analysisVariable'].apply(lambda val: val.split('.')[1])\n",
    "    \n",
    "    # drop any variable name duplicates\n",
    "    enrich_df = enrich_df.drop_duplicates('variable_name')\n",
    "    \n",
    "    # flag variables from the input\n",
    "    var_match = enrich_df['variable_name'].apply(lambda var_name: var_name in variable_list_to_lookup)\n",
    "    \n",
    "    # create a dataframe of just the matching variables\n",
    "    alias_df = enrich_df[var_match]\n",
    "    \n",
    "    # filter out only needed columns\n",
    "    alias_df = alias_df[['variable_name', 'analysisVariable', 'alias']]\n",
    "    \n",
    "    # rename columns\n",
    "    alias_df.columns = ['variable_name', 'enrichment_name', 'alias_name']\n",
    "    \n",
    "    return alias_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_enrich_limits(gis):\n",
    "\n",
    "    # get the limitations for the enrichment service\n",
    "    limits_resp = gis._con.get(f'{gis.properties.helperServices.geoenrichment.url}/Geoenrichment/ServiceLimits')\n",
    "\n",
    "    # extract out and reformat the limits\n",
    "    limits_lst = limits_resp['serviceLimits']['value']\n",
    "    limits_dict = {itm['paramName']: itm['value'] for itm in limits_lst}\n",
    "\n",
    "    # save the values into a named tuple\n",
    "    EnrichLimits = namedtuple('EnrichLimits', ['max_record_count', 'max_collections', 'max_fields'])\n",
    "    enrich_limits = EnrichLimits(limits_dict['maxRecordCount'], limits_dict['maximumDataCollections'], \n",
    "                                 limits_dict['maximumOutFieldsNumber'])\n",
    "    return enrich_limits\n",
    "\n",
    "\n",
    "def _enrich_to_csv(geo_df, var_lst, gis):\n",
    "    temp_csv = f'{temp_file_root}_{uuid.uuid4().hex}.csv'\n",
    "    enrich_df = _enrich_wrapper(geo_df, var_lst, gis)\n",
    "    enrich_df.to_csv(temp_csv)\n",
    "    return temp_csv\n",
    "\n",
    "def _enrich_wrapper(geo_df, variable_lst, gis):\n",
    "    enrich_limits = get_enrich_limits(gis)\n",
    "\n",
    "    var_df = pd.DataFrame([[var] + var.split('.') for var in enrich_lst], columns=['enrich_var', 'collection', 'var_name'])\n",
    "    collections = var_df.collection.unique()\n",
    "    collection_cnt = collections.size\n",
    "\n",
    "    if collection_cnt > enrich_limits.max_collections:\n",
    "\n",
    "        enrich_var_blocks = [list(var_df[var_df['collection'].isin(collections[idx:idx + enrich_limits.max_collections])]['enrich_var'].values)\n",
    "                             for idx in range(0, collection_cnt,  enrich_limits.max_collections)]\n",
    "\n",
    "        enrich_df_lst = [geoenrichment.enrich(geo_df.copy(), analysis_variables=enrich_block, return_geometry=False)\n",
    "                         for enrich_block in enrich_var_blocks]\n",
    "\n",
    "        enrich_df = reduce(lambda left,right: pd.merge(left,right), enrich_df_lst)\n",
    "\n",
    "        enrich_df = enrich_df[[geo_id_fld] + list(var_df['var_name'])].copy()\n",
    "        \n",
    "        return enrich_df\n",
    "\n",
    "    \n",
    "def enrich(input_data, input_data_id_col, variable_list, gis):\n",
    "        # get the data into a dataframe\n",
    "        geo_df = utils.get_dataframe(input_data)\n",
    "        \n",
    "        # get the limitations on the enrichment rest endpoint, and scale the analysis based on this\n",
    "        enrich_limits = get_enrich_limits(gis)\n",
    "        max_records = enrich_limits.max_record_count\n",
    "\n",
    "        # if necessary, batch the analysis based on the size of the input data, and the number of destinations per origin\n",
    "        if len(geo_df.index) > max_records:\n",
    "\n",
    "            # process each batch, and save the results to a temp file in the temp directory\n",
    "            enrich_csv_list = [_enrich_to_csv(geo_df.iloc[idx:idx + max_records], variable_list, gis)\n",
    "                                for idx in range(0, len(origin_df.index), max_origin_cnt)]\n",
    "\n",
    "            # load all the temporary files into dataframes and combine them into a single dataframe\n",
    "            enrich_df = pd.concat([pd.read_csv(enrich_csv) for enrich_csv in enrich_csv_list])\n",
    "\n",
    "            # clean up the temp files\n",
    "            for csv_file in enrich_csv_list:\n",
    "                os.remove(csv_file)\n",
    "\n",
    "        else:\n",
    "            enrich_df = _enrich_wrapper(geo_df, variable_list, gis)\n",
    "            \n",
    "        # get a list of just the columns requested\n",
    "        col_lst = [input_data_id_col] + [var.split('.')[1] for var in variable_list]\n",
    "            \n",
    "        return enrich_df[col_lst].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410050201001000</td>\n",
       "      <td>{\"rings\": [[[-122.65566145899999, 45.426378462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410050201001001</td>\n",
       "      <td>{\"rings\": [[[-122.65534145899994, 45.427037462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410050201001002</td>\n",
       "      <td>{\"rings\": [[[-122.65548645999996, 45.429533462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410050201001003</td>\n",
       "      <td>{\"rings\": [[[-122.65696245999999, 45.428736462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410050201001004</td>\n",
       "      <td>{\"rings\": [[[-122.65702845999999, 45.428751462...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GEOID                                              SHAPE\n",
       "0  410050201001000  {\"rings\": [[[-122.65566145899999, 45.426378462...\n",
       "1  410050201001001  {\"rings\": [[[-122.65534145899994, 45.427037462...\n",
       "2  410050201001002  {\"rings\": [[[-122.65548645999996, 45.429533462...\n",
       "3  410050201001003  {\"rings\": [[[-122.65696245999999, 45.428736462...\n",
       "4  410050201001004  {\"rings\": [[[-122.65702845999999, 45.428751462..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df = utils.get_dataframe(geo_fc)\n",
    "geo_df = geo_df[[geo_id_fld, 'SHAPE']].copy()\n",
    "geo_df.spatial.set_geometry('SHAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable count = 1,627\n",
      "\n",
      "['GQPOP_CY', 'GENALPHACY', 'GENZ_CY', 'MILLENN_CY', 'GENX_CY', 'BABYBOOMCY', 'OLDRGENSCY', 'GENBASE_CY', 'POP0_CY', 'POP5_CY', 'POP10_CY', 'POP15_CY', 'POP20_CY', 'POP25_CY', 'POP30_CY', 'POP35_CY', 'POP40_CY', 'POP45_CY', 'POP50_CY', 'POP55_CY']\n"
     ]
    }
   ],
   "source": [
    "vars_df = pd.read_csv(vars_csv, index_col=0)\n",
    "vars_df['variable_name'] = vars_df['variable_name'].str.upper()\n",
    "vars_df.drop_duplicates('variable_name')\n",
    "var_lst = list(vars_df['variable_name'].values)\n",
    "enrich_lst = get_online_variable_list(var_lst, ent_gis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "geo_df = geo_df_full.iloc[:1500].copy()\n",
    "geo_df.spatial.set_geometry('SHAPE')\n",
    "enrich_df = enrich(geo_df, geo_id_fld, enrich_lst, ent_gis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enrich_df = enrich_data(geo_df, enrich_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>FAGE0_CY</th>\n",
       "      <th>FAGE1_CY</th>\n",
       "      <th>FAGE2_CY</th>\n",
       "      <th>FAGE3_CY</th>\n",
       "      <th>FAGE4_CY</th>\n",
       "      <th>FAGE5_CY</th>\n",
       "      <th>FAGE6_CY</th>\n",
       "      <th>FAGE7_CY</th>\n",
       "      <th>FAGE8_CY</th>\n",
       "      <th>...</th>\n",
       "      <th>ACSUNT1ATT</th>\n",
       "      <th>ACSUNT2</th>\n",
       "      <th>ACSUNT3</th>\n",
       "      <th>ACSUNT5</th>\n",
       "      <th>ACSUNT10</th>\n",
       "      <th>ACSUNT20</th>\n",
       "      <th>ACSUNT50UP</th>\n",
       "      <th>ACSUNTMOB</th>\n",
       "      <th>ACSUNTOTH</th>\n",
       "      <th>ACSBLT2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410050201001000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410050201001001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410050201001002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410050201001003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410050201001004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>410050201001005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>410050201001006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>410050201001007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>410050201001008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>410050201001009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             GEOID  FAGE0_CY  FAGE1_CY  FAGE2_CY  FAGE3_CY  FAGE4_CY  \\\n",
       "0  410050201001000         0         0         0         0         0   \n",
       "1  410050201001001         0         0         0         0         0   \n",
       "2  410050201001002         0         0         0         0         0   \n",
       "3  410050201001003         0         0         0         0         0   \n",
       "4  410050201001004         0         0         0         0         0   \n",
       "5  410050201001005         0         0         0         0         0   \n",
       "6  410050201001006         0         0         0         0         0   \n",
       "7  410050201001007         0         0         0         0         0   \n",
       "8  410050201001008         0         0         0         0         0   \n",
       "9  410050201001009         0         0         0         0         0   \n",
       "\n",
       "   FAGE5_CY  FAGE6_CY  FAGE7_CY  FAGE8_CY     ...      ACSUNT1ATT  ACSUNT2  \\\n",
       "0         0         0         0         0     ...               0        0   \n",
       "1         0         0         0         0     ...               0        0   \n",
       "2         0         0         0         0     ...               2        0   \n",
       "3         0         0         0         0     ...               0        0   \n",
       "4         0         0         0         0     ...               0        0   \n",
       "5         0         0         0         0     ...               0        0   \n",
       "6         0         0         0         0     ...               1        0   \n",
       "7         0         0         0         0     ...               0        0   \n",
       "8         0         0         0         1     ...               3        0   \n",
       "9         0         0         0         0     ...               0        0   \n",
       "\n",
       "   ACSUNT3  ACSUNT5  ACSUNT10  ACSUNT20  ACSUNT50UP  ACSUNTMOB  ACSUNTOTH  \\\n",
       "0        0        0         0         0           0          0          0   \n",
       "1        0        0         0         0           0          0          0   \n",
       "2        0        0         0         0           0          0          0   \n",
       "3        0        0         0         0           0          0          0   \n",
       "4        0        0         0         0           0          0          0   \n",
       "5        0        0         0         0           0          0          0   \n",
       "6        0        0         0         0           0          0          0   \n",
       "7        0        0         0         0           0          0          0   \n",
       "8        0        1         0         0           0          0          0   \n",
       "9        0        0         0         0           0          0          0   \n",
       "\n",
       "   ACSBLT2010  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "\n",
       "[10 rows x 1209 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "enrich_limits = get_enrich_limits(ent_gis)\n",
    "\n",
    "var_df = pd.DataFrame([[var] + var.split('.') for var in enrich_lst], columns=['enrich_var', 'collection', 'var_name'])\n",
    "collections = var_df.collection.unique()\n",
    "collection_cnt = collections.size\n",
    "\n",
    "if collection_cnt > enrich_limits.max_collections:\n",
    "    \n",
    "    enrich_var_blocks = [list(var_df[var_df['collection'].isin(collections[idx:idx + enrich_limits.max_collections])]['enrich_var'].values)\n",
    "                         for idx in range(0, collection_cnt,  enrich_limits.max_collections)]\n",
    "    \n",
    "    enrich_df_lst = [enrich(geo_df.copy(), analysis_variables=enrich_block, return_geometry=False)\n",
    "                     for enrich_block in enrich_var_blocks]\n",
    "    \n",
    "    enrich_df = reduce(lambda left,right: pd.merge(left,right), enrich_df_lst)\n",
    "    \n",
    "    enrich_df = enrich_df[[geo_id_fld] + list(var_df['var_name'])].copy()\n",
    "\n",
    "enrich_df"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "10.7.1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
